{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pickle\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import LSTM\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.optimizers import RMSprop, Adam\n",
    "from keras.utils import np_utils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "fn = 'data/shakespeare.txt'\n",
    "sentences = []\n",
    "all_chars = []\n",
    "with open(fn, 'r') as f:\n",
    "    for line in f:\n",
    "        if len(line.strip()) > 3:\n",
    "            if line[:2] == '  ': line = line[2:]\n",
    "            sentences.append(line.lower())\n",
    "            all_chars += list(line.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total characters: 93673\n",
      "Total vocab: 38\n"
     ]
    }
   ],
   "source": [
    "# Create vocabulary.\n",
    "chars = sorted(list(set(all_chars)))\n",
    "char_to_int = dict((c, i) for i, c in enumerate(chars))\n",
    "int_to_char = dict((i, c) for i, c in enumerate(chars))\n",
    "\n",
    "n_chars = len(all_chars)\n",
    "n_vocab = len(chars)\n",
    "print('Total characters: %d' % n_chars)\n",
    "print('Total vocab: %d' % n_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total patterns: 31211\n"
     ]
    }
   ],
   "source": [
    "# Construct dataset.\n",
    "seq_len = 40\n",
    "step_size = 3\n",
    "dataX = []\n",
    "dataY = []\n",
    "for i in range(0, n_chars - seq_len, step_size):\n",
    "    seq_in = all_chars[i: i + seq_len]\n",
    "    seq_out = all_chars[i + seq_len]\n",
    "    dataX.append([char_to_int[char] for char in seq_in])\n",
    "    dataY.append(char_to_int[seq_out])\n",
    "n_patterns = len(dataX)\n",
    "print('Total patterns: %d' % n_patterns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.reshape(dataX, (n_patterns, seq_len, 1))\n",
    "X = X / float(n_vocab)\n",
    "y = np_utils.to_categorical(dataY)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_6 (LSTM)                (None, 128)               66560     \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 38)                4902      \n",
      "=================================================================\n",
      "Total params: 71,462\n",
      "Trainable params: 71,462\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(LSTM(128, input_shape=(X.shape[1], X.shape[2])))\n",
    "model.add(Dense(y.shape[1], activation='softmax'))\n",
    "optimizer = Adam(learning_rate=0.01)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath = 'weights-improvement-{epoch:02d}-{loss:.4f}.hdf5'\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='loss', verbose=1, save_best_only=True, mode='min')\n",
    "callbacks_list = [checkpoint]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 161/165\n",
      "31211/31211 [==============================] - 8s 251us/step - loss: 1.3361 - accuracy: 0.5817\n",
      "Epoch 162/165\n",
      "31211/31211 [==============================] - 8s 249us/step - loss: 1.3156 - accuracy: 0.5864\n",
      "Epoch 163/165\n",
      "31211/31211 [==============================] - 8s 249us/step - loss: 1.2686 - accuracy: 0.6014\n",
      "Epoch 164/165\n",
      "31211/31211 [==============================] - 8s 249us/step - loss: 1.2399 - accuracy: 0.6142\n",
      "Epoch 165/165\n",
      "31211/31211 [==============================] - 8s 249us/step - loss: 1.3114 - accuracy: 0.5867\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x7f8f822b1550>"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X, y, epochs=165, batch_size=128, initial_epoch=160)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample(preds, temperature=1.0):\n",
    "    # Helper function to sample from a probability array\n",
    "    # Source: https://keras.io/examples/lstm_text_generation/\n",
    "    preds = np.asarray(preds).astype('float64')\n",
    "    preds = np.log(preds) / temperature\n",
    "    exp_preds = np.exp(preds)\n",
    "    preds = exp_preds / np.sum(exp_preds)\n",
    "    probas = np.random.multinomial(1, preds, 1)\n",
    "    return np.argmax(probas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = \"weights-improvement-19-1.9435.hdf5\"\n",
    "model.load_weights(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = \"shall i compare thee to a summer's day?\\n\"\n",
    "pattern = [char_to_int[char] for char in seed]\n",
    "output_seq = pattern"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = 1.0\n",
    "for i in range(1000):\n",
    "    x = np.reshape(pattern, (1, len(pattern), 1))\n",
    "    x = x / float(n_vocab)\n",
    "    prediction = model.predict(x, verbose=0)\n",
    "    #index = sample(prediction, temperature=tmp)\n",
    "    index = np.argmax(prediction)\n",
    "    pattern.append(index)\n",
    "    pattern = pattern[1:]\n",
    "    output_seq.append(index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shall i compare thee to a summer's day?\n",
      "ooy nowe nend eye sey suellc shat pnoa iooe to get,\n",
      "toeeter on turm cnmc siou drt fort theer brent,\n",
      "when io at thou some iey seyslnt somlld,\n",
      "that ho an bnl-\n",
      "bns the parter puoz ouecrire mfnd thu bioigr,\n",
      "what tomrdr each of madeid ooog aoteer,\n",
      "and then f sureeg'c cuente the srire coon,\n",
      "thet ttimte that ier booeer thanl by their stete,\n",
      "what somrdr me toae in torr in the rhnwe.\n",
      "thoce tome supaegss of deauty's fartane frowt,\n",
      "and to move shall whet i davtet to mh.\n",
      "that thou sha teysrec toatl of toy minht sheng,\n",
      "aut thou altntit than, then thou sha dvis,\n",
      "the earte coou thou drt thy siof, and yhuh mi,\n",
      "what thou sharo iiv stbtt wot,srmd somn miare,\n",
      "and shat bnue ou lassr aavnarg yourg,\n",
      "and shat in tore io torl aea bm b foenr,\n",
      "aut whete thou art bnth mu cupe ou lens,\n",
      "and bol hyer the sreer toure thoug thel pooiige slgte,\n",
      "and thenefore ane then e sapenuer comh,\n",
      "to tie poeer's fars frcehng hand dv theer ocys,\n",
      "ay as i hou feytery dremnid fyely drol.\n",
      "and aol the bmastir of mone to touti thee,\n",
      "io del\n"
     ]
    }
   ],
   "source": [
    "output = [int_to_char[i] for i in output_seq]\n",
    "output = ''.join(output)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31211/31211 [==============================] - 5s 163us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.2009560575030256, 0.628304123878479]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
